{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steel Defect Detection\n",
    "\n",
    "> POC from multiple Severstal Kaggle Competition solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from steel_segmentation.all import * \n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive, VBox, HBox\n",
    "from IPython.display import Image\n",
    "\n",
    "def opt_func(params, **kwargs): return OptimWrapper(params, torch.optim.Adam, **kwargs)\n",
    "def splitter(m): return convert_params([[m.encoder], [m.decoder], [m.segmentation_head]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_model_url = \"https://www.dropbox.com/s/f52j2u4trox0i6o/efficientnet-b2.pkl?dl=1\"\n",
    "exported_model = download_data(exported_model_url, \"export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = load_learner(exported_model, cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "  \n",
    "def get_label_defects(preds: torch.Tensor, groundtruth:bool=False) -> str:   \n",
    "    preds = preds.float()\n",
    "    zero_preds = torch.zeros(tuple(preds.shape)[1:])\n",
    "    detected_defects = torch.cat([zero_preds.unsqueeze(axis=0), preds])\n",
    "    idx_defects = detected_defects.argmax(0).unique()\n",
    "    argmax_defects = list(np.sort(idx_defects.numpy()))\n",
    "    \n",
    "    types_defects = [str(o) for o in argmax_defects][1:]\n",
    "    n_defects = len(types_defects)\n",
    "    \n",
    "    defects_word = \"defects\" if n_defects!=1 else \"defect\"\n",
    "    types_word = \"types\" if n_defects!=1 else \"type\"\n",
    "    preds_word = \"Ground truth\" if groundtruth else \"Predicted\"\n",
    "    if n_defects > 0:\n",
    "        return f\"{preds_word}: n°{n_defects} {defects_word} of {types_word}: {' '.join(types_defects)}\"\n",
    "    else:\n",
    "        return f\"{preds_word}: n°0 {defects_word}\"\n",
    "\n",
    "def segment_img(img, out_widget, lbl_widget, gt=None, gt_label=None):\n",
    "    rles, preds, probs = learner.predict(img)\n",
    "    lbl_widget.value = get_label_defects(preds)    \n",
    "    \n",
    "    img_np = np.array(img)\n",
    "    w,h,_ = img_np.shape\n",
    "    \n",
    "    out_widget.clear_output()\n",
    "    with out_widget: \n",
    "        plot_mask_image(\"Original\", img_np, np.zeros((w,h,4)))\n",
    "        \n",
    "        if not ((gt is None) or (gt_label is None)):\n",
    "            gt_label.value = get_label_defects(\n",
    "                torch.Tensor(gt).permute(2,0,1), \n",
    "                groundtruth=True\n",
    "            )\n",
    "            plot_mask_image(\"Ground Truth\", img_np, gt)\n",
    "            \n",
    "        plot_mask_image(\"Predicted\", np.array(img), preds.permute(1,2,0).float().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgid_list(img_path):\n",
    "    return [o.name for o in img_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training images with ground truth\n",
    "\n",
    "# Description\n",
    "description_train = widgets.Label('Select an image and compare the prediction with the \"ground truth\"')\n",
    "\n",
    "# Dropdown element\n",
    "style = {'description_width': 'initial'}\n",
    "imgid_elements_train = get_imgid_list(train_pfiles)\n",
    "imgid_dropdown_train = widgets.Dropdown(\n",
    "    options=imgid_elements_train, index=0, description=\"Select an Image:\", style=style)\n",
    "# Detect button\n",
    "btn_run_train = widgets.Button(description='Detect')\n",
    "btn_run_train.style.button_color = 'lightgreen'\n",
    "# Label for text output groundtruth\n",
    "lbl_ground_train = widgets.Label()\n",
    "# Label for text output\n",
    "lbl_pred_train = widgets.Label()\n",
    "# Plot output\n",
    "out_pl_train = widgets.Output()\n",
    "\n",
    "# final GUI\n",
    "training_box = VBox([\n",
    "    description_train,\n",
    "    HBox([imgid_dropdown_train, btn_run_train]), \n",
    "    lbl_ground_train,\n",
    "    lbl_pred_train,\n",
    "    out_pl_train], \n",
    "    style=style\n",
    ")\n",
    "\n",
    "# Actions\n",
    "def on_change_detect_train(change):\n",
    "    imageid = imgid_dropdown_train.value    \n",
    "    _, mask = make_mask(imageid)\n",
    "    \n",
    "    image_np = cv2.imread(str(train_path/imageid))\n",
    "    img = PILImage.create(image_np)\n",
    "    \n",
    "    segment_img(img, out_pl_train, lbl_pred_train, gt=mask, gt_label=lbl_ground_train)\n",
    "    \n",
    "btn_run_train.on_click(on_change_detect_train)\n",
    "imgid_dropdown_train.observe(on_change_detect_train, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "\n",
    "# Description\n",
    "description_test = widgets.Label('Select an image from the test set (no ground truth)')\n",
    "\n",
    "# Dropdown element\n",
    "style = {'description_width': 'initial'}\n",
    "imgid_elements_test = get_imgid_list(test_pfiles)\n",
    "imgid_dropdown_test = widgets.Dropdown(\n",
    "    options=imgid_elements_test, index=0, description=\"Select an Image:\", style=style)\n",
    "# Detect button\n",
    "btn_run_test = widgets.Button(description='Detect')\n",
    "btn_run_test.style.button_color = 'lightgreen'\n",
    "# Label for text output predictions\n",
    "lbl_pred_test = widgets.Label()\n",
    "# Plot output\n",
    "out_pl_test = widgets.Output()\n",
    "\n",
    "# final GUI\n",
    "testing_box = VBox([\n",
    "    description_test,\n",
    "    HBox([imgid_dropdown_test, btn_run_test]), \n",
    "    lbl_pred_test,\n",
    "    out_pl_test], \n",
    "    style=style)\n",
    "\n",
    "# Actions\n",
    "def on_change_detect_test(change):\n",
    "    imageid = imgid_dropdown_test.value    \n",
    "    \n",
    "    image_np = cv2.imread(str(test_path/imageid))\n",
    "    img = PILImage.create(image_np)\n",
    "    \n",
    "    segment_img(img, out_pl_test, lbl_pred_test)\n",
    "    \n",
    "btn_run_test.on_click(on_change_detect_test)\n",
    "imgid_dropdown_test.observe(on_change_detect_test, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload\n",
    "\n",
    "# Description\n",
    "description_label_upload = widgets.Label('Upload an image and detect')\n",
    "# Upload button\n",
    "btn_upload = widgets.FileUpload(multiple=False)\n",
    "# Detect button\n",
    "btn_run_upload = widgets.Button(description='Detect')\n",
    "btn_run_upload.style.button_color = 'lightgreen'\n",
    "# Clear button\n",
    "clear_upload = widgets.Button(description='Clear', button_style='danger')\n",
    "# Label for text output\n",
    "lbl_pred_upload = widgets.Label()\n",
    "# Plot output\n",
    "out_pl_upload = widgets.Output()\n",
    "\n",
    "# final GUI\n",
    "upload_box = VBox([description_label_upload, \n",
    "                   HBox([btn_upload, btn_run_upload, clear_upload]),\n",
    "                   lbl_pred_upload, \n",
    "                   out_pl_upload])\n",
    "\n",
    "# Actions\n",
    "def on_click_detect_uploaded(change):\n",
    "    img = PILImage.create(btn_upload.data[-1]) # new release .content.tobytes()\n",
    "    segment_img(img, out_pl_upload, lbl_pred_upload)\n",
    "    \n",
    "def on_click_clear_uploaded(change):\n",
    "    btn_upload._counter = 0\n",
    "    btn_upload.value.clear()\n",
    "    out_pl_upload.clear_output()\n",
    "    lbl_pred_upload.value = \"\"\n",
    "        \n",
    "btn_run_upload.on_click(on_click_detect_uploaded)\n",
    "clear_upload.on_click(on_click_clear_uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab = widgets.Tab()\n",
    "# tab.children = [upload_box, multi_choice_box]\n",
    "# tab.set_title(0, 'Upload validation')\n",
    "# tab.set_title(1, 'Multiple choice validation')\n",
    "# tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f272a99acae94b619df7b1133943a712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(Label(value='Select an image and compare the prediction with the \"ground tr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accordion = widgets.Accordion(\n",
    "    children=[training_box, testing_box, upload_box])\n",
    "\n",
    "accordion.set_title(0, 'Training images with ground truth')\n",
    "accordion.set_title(1, 'Test images validation')\n",
    "accordion.set_title(2, 'Upload validation')\n",
    "#accordion.set_title(2, 'Test validation')\n",
    "accordion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](logo.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
