{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steel Defect Detection\n",
    "\n",
    "> POC from multiple Severstal Kaggle Competition solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#![Steel Industry](img.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from steel_segmentation.all import * \n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive, VBox, HBox\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_func(params, **kwargs): return OptimWrapper(params, torch.optim.Adam, **kwargs)\n",
    "def splitter(m): return convert_params([[m.encoder], [m.decoder], [m.segmentation_head]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_model_url = \"https://www.dropbox.com/s/f52j2u4trox0i6o/efficientnet-b2.pkl?dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_model = download_data(exported_model_url, \"export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = load_learner(exported_model, cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgid_list = [o.name for o in train_pfiles]\n",
    "imgid_cond = train.ImageId.isin(imgid_list)\n",
    "df = train.loc[imgid_cond]\n",
    "imgid_elements = df.ImageId.drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "style = {'description_width': 'initial'}\n",
    "imgid_dropdown = widgets.Dropdown(options=imgid_elements, index=0, description=\"Select an Image:\", style=style)\n",
    "lbl_pred = widgets.Label()\n",
    "out_pl = widgets.Output()\n",
    "btn_run = widgets.Button(description='Detect')\n",
    "btn_run.style.button_color = 'lightgreen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "btn_upload = widgets.FileUpload(multiple=False)\n",
    "\n",
    "lbl_pred_upload = widgets.Label()\n",
    "out_pl_upload = widgets.Output()\n",
    "\n",
    "btn_run_upload = widgets.Button(description='Detect')\n",
    "btn_run_upload.style.button_color = 'lightgreen'\n",
    "\n",
    "clear_upload = widgets.Button(description='Clear', button_style='danger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defects(preds) -> str:\n",
    "    preds = preds.float()\n",
    "    \n",
    "    zero_preds = torch.zeros(tuple(preds.shape)[1:])\n",
    "    detected_defects = torch.cat([zero_preds.unsqueeze(axis=0), preds])\n",
    "    idx_defects = detected_defects.argmax(0).unique()\n",
    "    argmax_defects = list(np.sort(idx_defects.numpy()))\n",
    "    types_defects = [str(o) for o in argmax_defects][1:]\n",
    "    n_defects = len(types_defects)\n",
    "    \n",
    "    defects_word = \"defects\" if n_defects!=1 else \"defect\"\n",
    "    types_word = \"types\" if n_defects!=1 else \"type\"\n",
    "    if n_defects > 0:\n",
    "        return f\"Predicted: n°{n_defects} {defects_word} of {types_word}: {' '.join(types_defects)}\"\n",
    "    else:\n",
    "        return f\"Predicted: n°0 {defects_word}\"\n",
    "\n",
    "def segment_img(img, out_widget, lbl_widget, groundtruth=None):\n",
    "    rles, preds, probs = learner.predict(img)\n",
    "    title = get_defects(preds)\n",
    "    img_np = np.array(img)\n",
    "    w,h,_ = img_np.shape\n",
    "    \n",
    "    out_widget.clear_output()\n",
    "    with out_widget: \n",
    "        plot_mask_image(\"Original\", img_np, np.zeros((w,h,4)))\n",
    "        \n",
    "        if not (groundtruth is None): \n",
    "            plot_mask_image(\"Ground Truth\", img_np, groundtruth)\n",
    "            \n",
    "        plot_mask_image(\"Predicted\", np.array(img), preds.permute(1,2,0).float().numpy())\n",
    "        \n",
    "    lbl_widget.value = title\n",
    "    \n",
    "def on_click_detect(change):\n",
    "    img = PILImage.create(btn_upload.data[-1]) # new release .content.tobytes()\n",
    "    segment_img(img, out_pl_upload, lbl_pred_upload)\n",
    "    \n",
    "def on_click_clear(change):\n",
    "    btn_upload._counter = 0\n",
    "    btn_upload.value.clear()\n",
    "    out_pl_upload.clear_output()\n",
    "    lbl_pred_upload.value = \"\"\n",
    "        \n",
    "btn_run_upload.on_click(on_click_detect)\n",
    "clear_upload.on_click(on_click_clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "upload_label = widgets.Label('Upload an image and detect steel defects with a Deep Learning segmentation model')\n",
    "upload_box = VBox([upload_label, \n",
    "                   HBox([btn_upload, btn_run_upload, clear_upload]),\n",
    "                   lbl_pred_upload, \n",
    "                   out_pl_upload])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_change_show(change):\n",
    "    imageid = imgid_dropdown.value    \n",
    "    _, mask = make_mask(imageid)\n",
    "    \n",
    "    image_np = cv2.imread(str(train_path/imageid))\n",
    "    img = PILImage.create(image_np)\n",
    "    \n",
    "    segment_img(img, out_pl, lbl_pred, groundtruth=mask)\n",
    "    \n",
    "btn_run.on_click(on_change_show)\n",
    "imgid_dropdown.observe(on_change_show, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_choice_label = widgets.Label('Upload an image and detect steel defects with a Deep Learning segmentation model')\n",
    "multi_choice_box = VBox([HBox([imgid_dropdown, btn_run]), \n",
    "                         lbl_pred,\n",
    "                         out_pl], style=style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab = widgets.Tab()\n",
    "# tab.children = [upload_box, multi_choice_box]\n",
    "# tab.set_title(0, 'Upload validation')\n",
    "# tab.set_title(1, 'Multiple choice validation')\n",
    "# tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816abb9171534bb3b17f89f4506db9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(HBox(children=(Dropdown(description='Select an Image:', options=('72aaba8ad…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accordion = widgets.Accordion(children=[multi_choice_box, upload_box])\n",
    "accordion.set_title(0, 'Compare results')\n",
    "accordion.set_title(1, 'Upload validation')\n",
    "accordion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
