{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" width=\"150\" height=\"150\" src=\"logo.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rilevamento difetti superficiali nell’acciaio\n",
    "\n",
    "> Caso d'uso di IP4FVG - Nodo Data Analytics and Artificial Intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa applicazione permette di classificare e individuare difetti superficiali dell'acciaio attraverso l'utilizzo di algoritmi di Deep Learning per il *machine vision* (segmentazione immagini)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from steel_segmentation.all import * \n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive, VBox, HBox\n",
    "from IPython.display import Image\n",
    "\n",
    "def opt_func(params, **kwargs): return OptimWrapper(params, torch.optim.Adam, **kwargs)\n",
    "def splitter(m): return convert_params([[m.encoder], [m.decoder], [m.segmentation_head]])\n",
    "\n",
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data and models\n",
    "data_url = \"https://www.dropbox.com/s/wzdtphbtaouaet5/data.zip?dl=1\"\n",
    "data_path = untar_data(data_url, fname=\"data.zip\", dest=\".\")\n",
    "\n",
    "effnet_model_url = \"https://www.dropbox.com/s/f52j2u4trox0i6o/efficientnet-b2.pkl?dl=1\"\n",
    "effnet_model_path = download_data(effnet_model_url, \"effnet_export.pkl\")\n",
    "resnet_model_url = \"https://www.dropbox.com/s/qumn1dshh9b0154/resnet_export.pkl?dl=1\"\n",
    "resnet_model_path = download_data(resnet_model_url, \"resnet_export.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config selection\n",
    "models = [effnet_model_path, resnet_model_path]\n",
    "\n",
    "def select_learner(selection):\n",
    "    return load_learner(models[selection], cpu=True)\n",
    "\n",
    "model_radio = widgets.RadioButtons(\n",
    "    options=[\n",
    "        (\"Model 1\", 0), \n",
    "        (\"Model 2\", 1)\n",
    "    ],\n",
    "    value=1,\n",
    "    description=\"Deep Learning model:\",\n",
    "    style=style\n",
    ")\n",
    "\n",
    "thresh_sel = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.,\n",
    "    max=1.,\n",
    "    step=0.1,\n",
    "    description='Threshold:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "pixels_sel = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=5000,\n",
    "    step=100,\n",
    "    description='Minimum pixel for defects:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    "    style=style\n",
    ")\n",
    "\n",
    "learner = select_learner(model_radio.value)\n",
    "\n",
    "def on_change_model(change):\n",
    "    global learner\n",
    "    learner = select_learner(model_radio.value)\n",
    "model_radio.observe(on_change_model, names='value')\n",
    "\n",
    "config_box = VBox([\n",
    "    model_radio,\n",
    "    thresh_sel,\n",
    "    pixels_sel\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored.\n",
    "    \"\"\"\n",
    "    def post_process_channel(p):\n",
    "        mask = cv2.threshold(p, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "        num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "        predictions = np.zeros((256, 1600), np.float32)\n",
    "\n",
    "        for c in range(1, num_component):\n",
    "            p = (component == c)\n",
    "            if p.sum() > min_size:\n",
    "                predictions[p] = 1\n",
    "\n",
    "        return torch.Tensor(predictions)\n",
    "    \n",
    "    preds_list = []\n",
    "    probs = probability.numpy()\n",
    "    n = probs.shape[0]\n",
    "    for ch in range(n):\n",
    "        prob = post_process_channel(probs[ch])\n",
    "        preds_list.append(prob)\n",
    "    \n",
    "    return torch.stack(preds_list, dim=0)\n",
    "\n",
    "def get_label_defects(preds: torch.Tensor, groundtruth:bool=False) -> str:   \n",
    "    preds = preds.float()\n",
    "    zero_preds = torch.zeros(tuple(preds.shape)[1:])\n",
    "    detected_defects = torch.cat([zero_preds.unsqueeze(axis=0), preds])\n",
    "    idx_defects = detected_defects.argmax(0).unique()\n",
    "    argmax_defects = list(np.sort(idx_defects.numpy()))\n",
    "    \n",
    "    types_defects = [str(o) for o in argmax_defects][1:]\n",
    "    n_defects = len(types_defects)\n",
    "    \n",
    "    defects_word = \"defects\" if n_defects!=1 else \"defect\"\n",
    "    types_word = \"types\" if n_defects!=1 else \"type\"\n",
    "    preds_word = \"Ground truth\" if groundtruth else \"Predicted\"\n",
    "    if n_defects > 0:\n",
    "        return f\"<b>{preds_word}</b>: n°<i>{n_defects}</i> {defects_word} of {types_word}: <i>{' '.join(types_defects)}</i>\"\n",
    "    else:\n",
    "        return f\"<b>{preds_word}</b>: n°0 {defects_word}\"\n",
    "\n",
    "def segment_img(\n",
    "    img, \n",
    "    out_widget, lbl_widget, \n",
    "    thresh_sel, pixels_sel,\n",
    "    gt_mask=None, gt_label=None\n",
    "):\n",
    "    threshold = thresh_sel.value\n",
    "    min_size = pixels_sel.value\n",
    "    \n",
    "    rles, preds, probs = learner.predict(img)\n",
    "    \n",
    "    img_np = np.array(img)\n",
    "    w,h,_ = img_np.shape\n",
    "    \n",
    "    out_widget.clear_output()\n",
    "    with out_widget: \n",
    "        plot_mask_image(\"Original\", img_np, np.zeros((w,h,4)))\n",
    "        \n",
    "        if not ((gt_mask is None) or (gt_label is None)):\n",
    "            gt_label.value = get_label_defects(\n",
    "                torch.Tensor(gt_mask).permute(2,0,1), \n",
    "                groundtruth=True) + \" | \"\n",
    "            plot_mask_image(\"Ground Truth\", img_np, gt_mask)\n",
    "            \n",
    "        post_processed_preds = post_process(probs, threshold, min_size)\n",
    "        lbl_widget.value = get_label_defects(post_processed_preds)      \n",
    "        plot_mask_image(\"Predicted\", np.array(img), post_processed_preds.permute(1,2,0).float().numpy())\n",
    "        \n",
    "def get_imgid_list(img_path):\n",
    "    return [o.name for o in img_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training images with ground truth\n",
    "\n",
    "# Description\n",
    "description_train = widgets.Label('Predict the defects and compare the results with the labels (ground truth).')\n",
    "\n",
    "# Dropdown element\n",
    "imgid_elements_train = get_imgid_list(train_pfiles)\n",
    "imgid_dropdown_train = widgets.Dropdown(\n",
    "    options=imgid_elements_train, index=0, description=\"Select an Image:\", style=style)\n",
    "# Detect button\n",
    "btn_run_train = widgets.Button(description='Detect')\n",
    "btn_run_train.style.button_color = 'lightgreen'\n",
    "# Label for text output groundtruth\n",
    "lbl_ground_train = widgets.HTML() #widgets.Label()\n",
    "# Label for text output\n",
    "lbl_pred_train = widgets.HTML() #widgets.Label()\n",
    "# Plot output\n",
    "out_pl_train = widgets.Output()\n",
    "\n",
    "# final GUI\n",
    "training_box = VBox([\n",
    "    description_train,\n",
    "    HBox([imgid_dropdown_train, btn_run_train]), \n",
    "    HBox([\n",
    "        lbl_ground_train,\n",
    "        lbl_pred_train\n",
    "    ]),\n",
    "    out_pl_train],\n",
    "    style=style\n",
    ")\n",
    "\n",
    "# Actions\n",
    "def on_change_detect_train(change):\n",
    "    imageid = imgid_dropdown_train.value    \n",
    "    _, mask = make_mask(imageid)\n",
    "    \n",
    "    image_np = cv2.imread(str(train_path/imageid))\n",
    "    img = PILImage.create(image_np)\n",
    "    \n",
    "    segment_img(\n",
    "        img, \n",
    "        out_pl_train, lbl_pred_train, \n",
    "        thresh_sel, pixels_sel, \n",
    "        gt_mask=mask, gt_label=lbl_ground_train\n",
    "    )\n",
    "    \n",
    "btn_run_train.on_click(on_change_detect_train)\n",
    "imgid_dropdown_train.observe(on_change_detect_train, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images\n",
    "\n",
    "# Description\n",
    "description_test = widgets.Label('Predict the defects from test images (without labels).')\n",
    "\n",
    "# Dropdown element\n",
    "style = {'description_width': 'initial'}\n",
    "imgid_elements_test = get_imgid_list(test_pfiles)\n",
    "imgid_dropdown_test = widgets.Dropdown(\n",
    "    options=imgid_elements_test, index=0, description=\"Select an Image:\", style=style)\n",
    "# Detect button\n",
    "btn_run_test = widgets.Button(description='Detect')\n",
    "btn_run_test.style.button_color = 'lightgreen'\n",
    "# Label for text output predictions\n",
    "lbl_pred_test = widgets.HTML() #widgets.Label()\n",
    "# Plot output\n",
    "out_pl_test = widgets.Output()\n",
    "\n",
    "# final GUI\n",
    "testing_box = VBox([\n",
    "    description_test,\n",
    "    HBox([imgid_dropdown_test, btn_run_test]), \n",
    "    lbl_pred_test,\n",
    "    out_pl_test], \n",
    "    style=style)\n",
    "\n",
    "# Actions\n",
    "def on_change_detect_test(change):\n",
    "    imageid = imgid_dropdown_test.value    \n",
    "    \n",
    "    image_np = cv2.imread(str(test_path/imageid))\n",
    "    img = PILImage.create(image_np)\n",
    "    \n",
    "    segment_img(\n",
    "        img, \n",
    "        out_pl_test, lbl_pred_test,\n",
    "        thresh_sel, pixels_sel\n",
    "    )\n",
    "    \n",
    "btn_run_test.on_click(on_change_detect_test)\n",
    "imgid_dropdown_test.observe(on_change_detect_test, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload\n",
    "\n",
    "# Description\n",
    "description_label_upload = widgets.Label('Upload an image and predict the defects.')\n",
    "# Upload button\n",
    "btn_upload = widgets.FileUpload(multiple=False)\n",
    "# Detect button\n",
    "btn_run_upload = widgets.Button(description='Detect')\n",
    "btn_run_upload.style.button_color = 'lightgreen'\n",
    "# Clear button\n",
    "clear_upload = widgets.Button(description='Clear', button_style='danger')\n",
    "# Label for text output\n",
    "lbl_pred_upload = widgets.HTML() #widgets.Label()\n",
    "# Plot output\n",
    "out_pl_upload = widgets.Output()\n",
    "\n",
    "# final GUI\n",
    "upload_box = VBox([description_label_upload, \n",
    "                   HBox([btn_upload, btn_run_upload, clear_upload]),\n",
    "                   lbl_pred_upload, \n",
    "                   out_pl_upload])\n",
    "\n",
    "# Actions\n",
    "def on_click_detect_uploaded(change):\n",
    "    img = PILImage.create(btn_upload.data[-1]) # new release .content.tobytes()\n",
    "    segment_img(\n",
    "        img, \n",
    "        out_pl_upload, lbl_pred_upload,\n",
    "        thresh_sel, pixels_sel\n",
    "    )\n",
    "    \n",
    "def on_click_clear_uploaded(change):\n",
    "    btn_upload._counter = 0\n",
    "    btn_upload.value.clear()\n",
    "    out_pl_upload.clear_output()\n",
    "    lbl_pred_upload.value = \"\"\n",
    "        \n",
    "btn_run_upload.on_click(on_click_detect_uploaded)\n",
    "clear_upload.on_click(on_click_clear_uploaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab = widgets.Tab()\n",
    "# tab.children = [upload_box, multi_choice_box]\n",
    "# tab.set_title(0, 'Upload validation')\n",
    "# tab.set_title(1, 'Multiple choice validation')\n",
    "# tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a692dfd0ec943e9b1f085d111d50286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(RadioButtons(description='Select a model:', index=1, options=(('Model 1', 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "box_lbls = ['Configuration', 'Detect and compare', 'Validate', 'Upload']\n",
    "\n",
    "accordion = widgets.Accordion(\n",
    "    children=[config_box, training_box, testing_box, upload_box],\n",
    "    selected_index=1\n",
    ")\n",
    "\n",
    "for i, lbl in enumerate(box_lbls):\n",
    "    accordion.set_title(i, lbl)\n",
    "\n",
    "accordion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Riferimenti:**\n",
    "- Documentazione tecnica: [steel_segmentation](https://marcomatteo.github.io/steel_segmentation/)\n",
    "- Dataset utilizzato: [Severstal Competition, Kaggle](https://www.kaggle.com/c/severstal-steel-defect-detection/overview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
